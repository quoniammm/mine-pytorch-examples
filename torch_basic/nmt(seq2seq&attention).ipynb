{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from cuda_functional import SRU, SRUCell\n",
    "\n",
    "import re\n",
    "import tqdm\n",
    "import jieba\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "path = './data/cmn-eng/'\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isChinese(sen):\n",
    "    zhPattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "    return zhPattern.search(sen)\n",
    "# 简化句子 便于处理\n",
    "def normalize_string(s):\n",
    "    s = re.sub(r\"[!！？.()（）\"\"?。“”，,']\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        sen_list = []\n",
    "        if isChinese(sentence):\n",
    "            sen_list = jieba.cut(sentence)\n",
    "        else:\n",
    "            sen_list = sentence.split(' ')\n",
    "            \n",
    "        for word in sen_list:\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sen(path, lang1, lang2, reverse=False):\n",
    "    with open(path + '{}-{}.txt'.format(lang1, lang2)) as f:\n",
    "        lines = f.readlines()\n",
    "        pairs = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if reverse:\n",
    "                line = line.split('\\t')\n",
    "                line.reverse()\n",
    "                line = \"\\t\".join(line)\n",
    "                \n",
    "            pair = [normalize_string(sen) for sen in line.split('\\t')]\n",
    "            pairs.append(pair)\n",
    "        \n",
    "        if reverse:\n",
    "            input_lang = Lang(lang2)\n",
    "            output_lang = Lang(lang1) \n",
    "        else:\n",
    "            input_lang = Lang(lang1)            \n",
    "            output_lang = Lang(lang2)   \n",
    "            \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read lines......\n",
      "Trimmed  to 19056 sentence pairs\n",
      "Indexing words......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.696 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I found a beautiful shell on the shore ', '我在海滩上发现了一个漂亮的贝壳 ']\n",
      "['She is going to wash the bike this afternoon ', '她下午会洗自行车 ']\n",
      "['It s been a long war ', '这是场长久的战争 ']\n",
      "['There was a heavy rain last night ', '昨晚下大雨 ']\n",
      "['I m counting on your help ', '我指望你的帮助 ']\n"
     ]
    }
   ],
   "source": [
    "def data_preprocess(path, lang1, lang2, reverse=False):\n",
    "    print(\"Read lines......\")\n",
    "    input_lang, output_lang, pairs = read_sen(path, lang1, lang2, reverse)\n",
    "    print(\"Trimmed  to {} sentence pairs\".format(len(pairs)))\n",
    "    \n",
    "    print(\"Indexing words......\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "    \n",
    "input_lang, output_lang, pairs = data_preprocess(path, 'eng', 'cmn')\n",
    "for i in range(5):\n",
    "    print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.pytorch 搭建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.1.数据部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sen's index\n",
    "def ixs_from_sen(lang, sen):\n",
    "    if isChinese(lang):\n",
    "        sen = jieba.cut('')\n",
    "    else:\n",
    "        sen = sen.split(' ')\n",
    "        \n",
    "    return [lang.word2index[word] for word in sen]\n",
    "\n",
    "def var_from_sen(lang, sen):\n",
    "    ixs = ixs_from_sen(lang, sen)\n",
    "    ixs.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(ixs).view(-1, 1))\n",
    "    if USE_CUDA: \n",
    "        var = var.cuda()\n",
    "    \n",
    "    return var\n",
    "    \n",
    "\n",
    "def var_from_pair(pair):\n",
    "    input_variable = var_from_sen(in)\n",
    "    input_variable = \n",
    "\n",
    "    return (input_variable, output_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.2.模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.3.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
